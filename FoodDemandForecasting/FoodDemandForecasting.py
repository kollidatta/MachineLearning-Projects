# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yDN5EDz1Zu5Pot89aAdSUhnAL407qpmh
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv('train.csv')
meal = pd.read_csv('meal_info.csv')
ful_cent_info = pd.read_csv('fulfilment_center_info.csv')
test = pd.read_csv('test.csv')

data.shape, test.shape

train = data.iloc[:, :-1]
y = data.iloc[:,-1]
train.head()



df = pd.concat([train,test],axis =0)

df.head()

meal.head()

train= df.merge(meal,on = 'meal_id', how = 'left' )
train.head(1), train.shape

train = train.merge(ful_cent_info, on = 'center_id',how = 'left')
train.shape

train.columns

df_train = train

df_ = pd.get_dummies(df_train['center_type'])

df_

def cat_onehotencoder(df_concat):
    df_temp = df_concat
    for col in df_temp:
        if df_temp[col].dtype =='object':
            df1 = pd.get_dummies(df_concat[col], drop_first = True)
            df_concat.drop([col], axis = 1, inplace = True)
            
            df_concat = pd.concat([df_concat,df1], axis = 1)
        
    
        
    
    return df_concat

df_final =  cat_onehotencoder(train)

df_final = df_final.drop(columns = ['TYPE_B', 'TYPE_C'])

df_final = pd.concat([df_final, df_], axis = 1)

# ['discount'] = ((['checkout_price'] - X['base_price']) /data['base_price'])*100
X, test = df_final.iloc[:456548, :], df_final.iloc[456548:, :]

X.shape, test.shape

X.shape, y.shape

import seaborn as sns
import matplotlib.pyplot as plt

correlations = df_final[df_final.columns].corr(method = 'kendall')
plt.figure(figsize=(16,16))
sns.heatmap(correlations)

print('Absolute overall correlations')
print('-' * 30)
correlations_abs_sum = correlations[correlations.columns].abs().sum()
print(correlations_abs_sum, '\n')

print('Weakest correlations')
print('-' * 30)
print(correlations_abs_sum.nsmallest(5))



X = X.drop(columns = ['id', 'region_code', 'meal_id'])

X.shape, y.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 0)



X_train.shape, y_train.shape

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

X_train

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor()
rf.fit(X_train,y_train)

y_pred = rf.predict(X_test)

import math 
y_pred_f = [math.floor(i) for i in y_pred]
y_pred_f

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_log_error, mean_squared_error, explained_variance_score
from sklearn.metrics import r2_score

print('Train Score :',rf.score(X_train,y_train))
print('Test Score :',rf.score(X_test,y_test))

print('R squared :',(r2_score(y_test,y_pred_f)))
print('RMSLE :',np.sqrt(mean_squared_log_error(y_test,y_pred_f)))

from sklearn.tree import DecisionTreeRegressor
dcmodel = DecisionTreeRegressor()
dcmodel.fit(X_train, y_train)

y_pred_dc = dcmodel.predict(X_test)

y_pred_dc = [math.floor(i) for i in y_pred_dc]

print('Train Score :',dcmodel.score(X_train,y_train))
print('Test Score :',dcmodel.score(X_test,y_test))

print('R squared :',(r2_score(y_test,y_pred_dc)))
print('RMSLE :',np.sqrt(mean_squared_log_error(y_test,y_pred_dc)))

from sklearn.ensemble import GradientBoostingRegressor


GB_reg = GradientBoostingRegressor(max_depth = 4, n_estimators = 300)
GB_reg.fit(X_train, y_train)

y_pred_gb = GB_reg.predict(X_test)

y_pred_gb = [math.floor(i) for i in y_pred_gb]


print('Train Score :',GB_reg.score(X_train,y_train))
print('Test Score :',GB_reg.score(X_test,y_test))

print('R squared :',(r2_score(y_test,y_pred_gb)))
print('RMSLE :',np.sqrt(mean_squared_log_error(y_test,y_pred_gb)))